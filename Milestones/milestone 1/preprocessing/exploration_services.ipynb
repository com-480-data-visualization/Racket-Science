{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luna/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv files into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/\"\n",
    "dataset = \"huge_dataset/tennis_atp/\"\n",
    "\n",
    "atp1 = pd.read_csv(data_folder + dataset + \"atp_matches_2000.csv\")\n",
    "atp2 = pd.read_csv(data_folder + dataset + \"atp_matches_2001.csv\")\n",
    "atp3 = pd.read_csv(data_folder + dataset + \"atp_matches_2002.csv\")\n",
    "atp4 = pd.read_csv(data_folder + dataset + \"atp_matches_2003.csv\")\n",
    "atp5 = pd.read_csv(data_folder + dataset + \"atp_matches_2004.csv\")\n",
    "atp6 = pd.read_csv(data_folder + dataset + \"atp_matches_2005.csv\")\n",
    "atp7 = pd.read_csv(data_folder + dataset + \"atp_matches_2006.csv\")\n",
    "atp8 = pd.read_csv(data_folder + dataset + \"atp_matches_2007.csv\")\n",
    "atp9 = pd.read_csv(data_folder + dataset + \"atp_matches_2008.csv\")\n",
    "atp10 = pd.read_csv(data_folder + dataset + \"atp_matches_2009.csv\")\n",
    "atp11 = pd.read_csv(data_folder + dataset + \"atp_matches_2010.csv\")\n",
    "atp12 = pd.read_csv(data_folder + dataset + \"atp_matches_2011.csv\")\n",
    "atp13 = pd.read_csv(data_folder + dataset + \"atp_matches_2012.csv\")\n",
    "atp14 = pd.read_csv(data_folder + dataset + \"atp_matches_2013.csv\")\n",
    "atp15 = pd.read_csv(data_folder + dataset + \"atp_matches_2014.csv\")\n",
    "atp16 = pd.read_csv(data_folder + dataset + \"atp_matches_2015.csv\")\n",
    "atp17 = pd.read_csv(data_folder + dataset + \"atp_matches_2016.csv\")\n",
    "atp18 = pd.read_csv(data_folder + dataset + \"atp_matches_2017.csv\")\n",
    "atp19 = pd.read_csv(data_folder + dataset + \"atp_matches_2018.csv\")\n",
    "atp20 = pd.read_csv(data_folder + dataset + \"atp_matches_2019.csv\")\n",
    "atp21 = pd.read_csv(data_folder + dataset + \"atp_matches_2020.csv\")\n",
    "atp22 = pd.read_csv(data_folder + dataset + \"atp_matches_2021.csv\")\n",
    "atp23 = pd.read_csv(data_folder + dataset + \"atp_matches_2022.csv\")\n",
    "atp24 = pd.read_csv(data_folder + dataset + \"atp_matches_2023.csv\")\n",
    "atp25 = pd.read_csv(data_folder + dataset + \"atp_matches_2024.csv\")\n",
    "\n",
    "players = pd.read_csv(data_folder + dataset + \"atp_players.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "atp = pd.concat([atp1, atp2, atp3, atp4, atp5, atp6, atp7, atp8, atp9, atp10,\n",
    "                 atp11, atp12, atp13, atp14, atp15, atp16, atp17, atp19, atp20,\n",
    "                 atp21, atp22, atp23, atp24, atp25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "atp = atp25\n",
    "year = '2024'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interesting columns of this dataset to capture serving performance are : \n",
    "\n",
    "\n",
    "- **w_ace** (Winner's number of aces)  \n",
    "  - More aces generally indicate a strong server.  \n",
    "\n",
    "- **w_df** (Winner's number of double faults)  \n",
    "  - Too many double faults indicate inconsistency in serving.  \n",
    "\n",
    "- **w_svpt** (Winner's total serve points played)  \n",
    "  - Helps in calculating serve efficiency.  \n",
    "\n",
    "- **w_1stIn** (Winner's first serves made)  \n",
    "  - Higher values show how often the first serve goes in.  \n",
    "\n",
    "- **w_1stWon** (Winner's first-serve points won)  \n",
    "  - Shows effectiveness of first serves.  \n",
    "\n",
    "- **w_2ndWon** (Winner's second-serve points won)  \n",
    "  - Indicates reliability under pressure if the first serve fails.  \n",
    "\n",
    "- **w_SvGms** (Winner's service games played)  \n",
    "  - Allows calculation of serve performance per game.  \n",
    "\n",
    "- **w_bpSaved** (Winner's break points saved)  \n",
    "  - A strong server is good at saving break points.  \n",
    "\n",
    "- **w_bpFaced** (Winner's break points faced)  \n",
    "  - Fewer break points faced might indicate dominance on serve.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derived Metrics to Consider\n",
    "\n",
    "- **Ace Rate** = `w_ace / w_svpt`  \n",
    "- **First Serve %** = `w_1stIn / w_svpt`  \n",
    "- **First Serve Win %** = `w_1stWon / w_1stIn`  \n",
    "- **Second Serve Win %** = `w_2ndWon / (w_svpt - w_1stIn)`  \n",
    "- **Break Point Save %** = `w_bpSaved / w_bpFaced` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the **best server ever**, we aggregate these stats over an entire career and compare players.  \n",
    "Players with high ace rates, high first-serve win %, and strong break point save rates are likely the best servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 0 values with NaN to avoid division errors\n",
    "atp.replace(0, float('nan'), inplace=True)\n",
    "\n",
    "atp[\"w_Ace Rate\"] = atp[\"w_ace\"] / atp[\"w_svpt\"]\n",
    "atp[\"w_First Serve %\"] = atp[\"w_1stIn\"] / atp[\"w_svpt\"]\n",
    "atp[\"w_First Serve Win %\"] = atp[\"w_1stWon\"] / atp[\"w_1stIn\"]\n",
    "atp[\"w_Second Serve Win %\"] = atp[\"w_2ndWon\"] / (atp[\"w_svpt\"] - atp[\"w_1stIn\"])\n",
    "atp[\"w_Break Point Save %\"] = atp[\"w_bpSaved\"] / atp[\"w_bpFaced\"]\n",
    "\n",
    "atp[\"l_Ace Rate\"] = atp[\"l_ace\"] / atp[\"l_svpt\"]\n",
    "atp[\"l_First Serve %\"] = atp[\"l_1stIn\"] / atp[\"l_svpt\"]\n",
    "atp[\"l_First Serve Win %\"] = atp[\"l_1stWon\"] / atp[\"l_1stIn\"]\n",
    "atp[\"l_Second Serve Win %\"] = atp[\"l_2ndWon\"] / (atp[\"l_svpt\"] - atp[\"l_1stIn\"])\n",
    "atp[\"l_Break Point Save %\"] = atp[\"l_bpSaved\"] / atp[\"l_bpFaced\"]\n",
    "\n",
    "# Create a unified dataset by stacking winner and loser data\n",
    "winners_df = atp[[\"winner_id\", \"w_Ace Rate\", \"w_First Serve %\", \"w_First Serve Win %\", \"w_Second Serve Win %\", \"w_Break Point Save %\"]].copy()\n",
    "losers_df = atp[[\"loser_id\", \"l_Ace Rate\", \"l_First Serve %\", \"l_First Serve Win %\", \"l_Second Serve Win %\", \"l_Break Point Save %\"]].copy()\n",
    "\n",
    "# Rename columns for consistency\n",
    "winners_df.columns = [\"player_id\", \"Ace Rate\", \"First Serve %\", \"First Serve Win %\", \"Second Serve Win %\", \"Break Point Save %\"]\n",
    "losers_df.columns = [\"player_id\", \"Ace Rate\", \"First Serve %\", \"First Serve Win %\", \"Second Serve Win %\", \"Break Point Save %\"]\n",
    "\n",
    "players_df = pd.concat([winners_df, losers_df])\n",
    "\n",
    "players_avg = players_df.groupby(\"player_id\").mean()\n",
    "\n",
    "players_avg.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times each player appears as a winner\n",
    "winner_counts = atp['winner_id'].value_counts()\n",
    "\n",
    "# Count the number of times each player appears as a loser\n",
    "loser_counts = atp['loser_id'].value_counts()\n",
    "\n",
    "player_match_counts = winner_counts.add(loser_counts, fill_value=0).astype(int)\n",
    "\n",
    "player_match_counts = player_match_counts.reset_index()\n",
    "player_match_counts.columns = ['player_id', 'num_matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg = players_avg.merge(player_match_counts, on='player_id', how='left')\n",
    "\n",
    "# Replace NaN with 0 (in case some players are missing from the count)\n",
    "players_avg['num_matches'] = players_avg['num_matches'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_matches = 30\n",
    "filtered_players = players_avg[players_avg['num_matches'] >= min_matches]\n",
    "\n",
    "best_servers = filtered_players.merge(players[['player_id', 'name_first', 'name_last']], on='player_id', how='left')\n",
    "\n",
    "# Sort by Ace Rate (or another serving metric)\n",
    "\n",
    "\n",
    "output_folder = f'results/services/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_category_csv(df, value_col, category, year, output_folder):\n",
    "    df['Player'] = df['name_first'] + ' ' + df['name_last']\n",
    "    out_df = df[['Player', value_col, 'num_matches']].copy()\n",
    "    out_df.to_csv(f\"{output_folder}{year}_{category}.csv\", index=False)\n",
    "\n",
    "min_matches = 30\n",
    "filtered_players = players_avg[players_avg['num_matches'] >= min_matches]\n",
    "best_servers = filtered_players.merge(\n",
    "    players[['player_id', 'name_first', 'name_last']], \n",
    "    on='player_id', how='left'\n",
    ")\n",
    "\n",
    "output_folder = f'results/services/'\n",
    "\n",
    "\n",
    "ace_rate = best_servers.sort_values(\"Ace Rate\", ascending=False)\n",
    "save_category_csv(ace_rate, 'Ace Rate', 'Ace Rate', year, output_folder)\n",
    "\n",
    "first_serve = best_servers.sort_values(\"First Serve %\", ascending=False)\n",
    "save_category_csv(first_serve, 'First Serve %', 'First Serve %', year, output_folder)\n",
    "\n",
    "first_serve_win = best_servers.sort_values(\"First Serve Win %\", ascending=False)\n",
    "save_category_csv(first_serve_win, 'First Serve Win %', 'First Serve Win %', year, output_folder)\n",
    "\n",
    "second_serve_win = best_servers.sort_values(\"Second Serve Win %\", ascending=False)\n",
    "save_category_csv(second_serve_win, \"Second Serve Win %\", 'Second Serve Win %', year, output_folder)\n",
    "\n",
    "break_point_serve = best_servers.sort_values(\"Break Point Save %\", ascending=False)\n",
    "save_category_csv(break_point_serve, 'Break Point Save %', 'Break Point Save %', year, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
